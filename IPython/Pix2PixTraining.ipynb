{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.utils as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm as tqdm\n",
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.configs import config\n",
    "from src.modules.srgan import data_utils as ds\n",
    "from src.modules.srgan.data_utils import HPATrainDatasetFromFolder, HPAValDatasetFromFolder, \\\n",
    "    RecursionTrainDatasetFromFolder, RecursionValDatasetFromFolder, display_transform\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pix2pix_options = EasyDict({\n",
    "    # experiment params\n",
    "    'name': 'experiment_name',                  # name of the experiment\n",
    "    'gpu_ids': [0],                             # used gpu ids\n",
    "    'checkpoints_dir': '../pix2pix_training',   # where to save the models\n",
    "    'epoch': 'latest',                          # model from which epoch to load\n",
    "    'load_iter': 0,                             # model from each iteration to load (overrides epoch setting)\n",
    "    'verbose': False,                           # is the model verbose\n",
    "    'suffix': '',                               # optional suffix\n",
    "    # model params\n",
    "    'input_nc': 1,                              # number of input channels\n",
    "    'output_nc': 3,                             # number of output channels\n",
    "    'ngf': 64,                                  # number of generator filters in the last conv layer\n",
    "    'ndf': 64,                                  # number of discriminator filters in the first conv layer\n",
    "    'netD': 'basic',                            # discriminator architecture [basic | n_layers | pixel]\n",
    "    'netG': 'resnet_9blocks',                   # generator architecture [resnet_9blocks | resnet_6blocks | unet_256 | unet_128]\n",
    "    'n_layers_D': 3,                            # only used if netD == n_layers\n",
    "    'norm': 'instance',                         # instance normalization or batch normalization\n",
    "    'init_type': 'normal',                      # network initialization [normal | xavier | kaiming | orthogonal]\n",
    "    'init_gain': 0.02,                          # scaling factor for normal, xavier and orthogonal\n",
    "    'no_dropout': False,                        # don't use dropout\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
